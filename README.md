# cs231n
这里主要记录了我在学习cs231过程中完成的assignments的代码,还包含一些自己整理的课程学习笔记，手推的公式，以及相一些python的库的学习内容和遇到的问题


## 课程主要学习内容
本课程主要是深入讲解了深度学习框架的细节问题，聚焦面向视觉识别任务（尤其是图像分类任务）的端到端学习模型。虽然是面向视觉的，但也是深度学习的经典公开课。这里给出了[课程主页](http://cs231n.stanford.edu/syllabus.html)以及相关的[课程安排](http://cs231n.stanford.edu/syllabus.html)  

##  assignments内容

### assignment1
在本作业中，将基于k-最近邻（k-Nearest Neighbor）或者SVM/Softmax分类器实践一个简单的图像分类流程。本作业的目标如下：


- 理解基本的图像分类流程和数据驱动方法（训练与预测阶段）。
- 理解训练、验证、测试分块，学会使用验证数据来进行超参数调优。
- 熟悉使用numpy来编写向量化代码。
- 实现并应用k-最近邻（k-NN）分类器。
- 实现并应用支持向量机（SVM）分类器。
- 实现并应用Softmax分类器。
- 实现并应用一个两层神经网络分类器。
- 理解以上分类器的差异和权衡之处。
- 基本理解使用更高层次表达相较于使用原始图像像素对算法性能的提升（例如：色彩直方图和梯度直方图HOG）。

### assignment2
在本作业中，你将练习编写反向传播代码，训练神经网络和卷积神经网络。本作业的目标如下：


- 理解神经网络及其分层结构。
- 理解并实现（向量化）反向传播。
- 实现多个用于神经网络最优化的更新方法。
- 实现用于训练深度网络的批量归一化（ batch normalization ）。
- 实现随机失活（dropout）。
- 进行高效的交叉验证并为神经网络结构找到最好的超参数。
- 理解卷积神经网络的结构，并积累在数据集上训练此类模型的经验。

### assingment3
在本作业中，你将实现循环网络，并将其应用于在微软的COCO数据库上进行图像标注。我们还会介绍TinyImageNet数据集，然后在这个数据集使用一个预训练的模型来查看图像梯度的不同应用。本作业的目标如下：

- 理解循环神经网络（RNN）的结构，知道它们是如何随时间共享权重来对序列进行操作的。
- 理解普通循环神经网络和长短基记忆（Long-Short Term Memory）循环神经网络之间的差异。
- 理解在测试时如何从RNN生成序列。
- 理解如何将卷积神经网络和循环神经网络结合在一起来实现图像标注。
- 理解一个训练过的卷积神经网络是如何用来从输入图像中计算梯度的。
- 进行高效的交叉验证并为神经网络结构找到最好的超参数。
- 实现图像梯度的不同应用，比如显著图，搞笑图像，类别可视化，特征反演和DeepDream。


## 参考
1.这里给出有中文字幕的[学习视频](https://space.bilibili.com/216720985/channel/detail?cid=32406) ，此前在网易公开课学习的链接已经失效(视频被下架),所以这里给出的是B站同款学习视频
2.在学习过程中也用到了知乎上整理的[cs231课程学习笔记翻译](https://zhuanlan.zhihu.com/p/21930884)  